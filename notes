
# MUST DO:
# TODO: Implement ADAM
# TODO: LTP seems to work in vitro, see if traub leads to LTD

# LOW PRIORITY:
# TODO: Dictionary to facilitate sweeping function (param = key, list = item)
# TODO: Make it possible to use fewer than N_I N_Rs
# TODO: Make N_R variable per layer
# TODO: Maximize according to minmax in train


I can maybe use random B for all early layers and adaptive/symmetric B for last layer
QUESTION FOR MEETING: B for shallow layers?
