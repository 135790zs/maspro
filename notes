
# MUST DO:

# LOW PRIORITY:
# TODO: Print time elapsed after every sample
# TODO: Make it possible to use fewer than N_I N_Rs
# TODO: Make N_R variable per layer
# TODO: Experiment with reducing randomness a priori
# TODO: Explore non-uniform synaptic delays
# TODO: Explore membrane potential reset
# TODO: Comment code

note usage of W^out_kj in pE/pz equation in supp equation 20. Needs solution


=========

send plot to Jaeger, Dirk and Marco if working
may email Bellec et al if concrete question

=========

Gradient hard/softcapping for reliable descent

==========

ADAM has a one-off bias. See which optimizer this now is. Or fix it later for correctness. To do that, wait until appyling DWs until the point where ADAM is updated. Just accumulate gradients. Drawback: can't see weight updates in state plot anymore. But I probably won't need to, and the resulting code is better.


==========

==========
* Read other eprop papers
* L is positive if larger than 1/N_out else negative

==========

* Check how Bellec aggregates DWs and such. Mean vs sum?
* Check Bellec's code to check peripherals.
* Fix Adam
* Online w/ low LR?
* Try get good initial performance.
* Try reduce spike rate initially, using dropout and weight scaling.
* Analyze behavior on simple data/net
